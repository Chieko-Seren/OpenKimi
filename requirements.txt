numpy>=1.20.0
nltk>=3.6.0
requests>=2.25.0
transformers>=4.30.0
torch>=2.0.0
sentence-transformers>=2.2.0
fastapi>=0.95.0
uvicorn[standard]>=0.20.0
python-dotenv>=1.0.0
# accelerate>=0.20.0 # Optional, for faster loading/inference
# bitsandbytes>=0.40.0 # Optional, for 8-bit/4-bit quantization 